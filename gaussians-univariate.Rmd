---
title: "Univariate Gaussians"
output: html_notebook
---

basic inverse cdf sampling with qnorm
```{r}
library(ggplot2)

#set random seeds and two uniform samples
set.seed(12)
m1_u1 = runif(1000)
set.seed(37)
m1_u2 = runif(1000)

#apply inverse CDF
m1_x = qnorm(m1_u1)
m1_y = qnorm(m1_u2)
df1 = data.frame(m1_x, m1_y)

#apply ks test
x = ks.test(m1_x, "pnorm")

#visualize distribution
ggplot(df1, aes(x=m1_x)) + geom_histogram(col = 'black', fill = 'lightblue',) + labs(title = "Inverse CDF Sampling Distribution", x = "Value Sampled", y = "Count")
ggplot(df1, aes(x = m1_x, y = m1_y)) + geom_point(col = "black") + labs(title = "2D Scatterplot of Inverse CDF Distribution", x = "x", y = "y")
ggplot(df1, aes(sample = m1_x)) + stat_qq(col = "red") + stat_qq_line() + labs(title = "Inverse CDF QQ-Plot")
(x)
```

box-muller transform method
```{r}
#set random seeds and two uniform samples
set.seed(45)
m2_u1 = runif(1000)
set.seed(63)
m2_u2 = runif(1000)

#apply inverse cdf of exponential
s = -log(m2_u1)
#apply inverse cdf of uniform
theta = 2*pi*m2_u2
#calculate distance from origin
r = sqrt(2*s)

#calculate sample coordinates
m2_x = r * cos(theta)
m2_y = r * sin(theta)
df2 = data.frame(m2_x, m2_y)

#apply ks test
y = ks.test(m2_y, "pnorm")

#Visualize distribution
ggplot(df2, aes(x=m2_x)) + geom_histogram(col = 'black', fill = 'lightblue',) + labs(title = "Box-Muller Sampling Distribution", x = "Value Sampled", y = "Count")
ggplot(df2, aes(x = m2_x, y = m2_y)) + geom_point(col = "black") + labs(title = "2D Scatterplot of Box-Muller Distribution", x = "x", y = "y")
ggplot(df2, aes(sample = m2_x)) + stat_qq(col = "red") + stat_qq_line() + labs(title = "Box-Muller QQ-Plot")
(y)
```


central limit thm method
```{r}
#set number of points
n_points = 1000
n_adds = 1000

#set matrix of uniform samples
set.seed(105)
random_matrix = matrix(runif(n_points * n_adds), nrow = n_adds, ncol = n_points)

#sum uniform samples
gaussians = colSums(random_matrix)

#rescale samples
gmean = n_adds / 2
gstd = sqrt(n_adds / 12)
rescaled_gaussians = (gaussians - gmean) / gstd
df3 = data.frame(rescaled_gaussians)

#apply ks test
z = ks.test(rescaled_gaussians, "pnorm")

#visualize distribution
ggplot(df3, aes(x = rescaled_gaussians)) + geom_histogram(col = 'black', fill = 'lightblue', bins = 5) + labs(title = "Central Limit Theorem Sampling Distribution", x = "Value Sampled", y = "Count")
ggplot(df3, aes(x = rescaled_gaussians)) + geom_histogram(col = 'black', fill = 'lightblue', bins = 10) + labs(title = "Central Limit Theorem Sampling Distribution", x = "Value Sampled", y = "Count")
ggplot(df3, aes(x = rescaled_gaussians)) + geom_histogram(col = 'black', fill = 'lightblue', bins = 25) + labs(title = "Central Limit Theorem Sampling Distribution", x = "Value Sampled", y = "Count")
ggplot(df3, aes(x = rescaled_gaussians)) + geom_histogram(col = 'black', fill = 'lightblue', bins = 50) + labs(title = "Central Limit Theorem Sampling Distribution", x = "Value Sampled", y = "Count")
ggplot(df3, aes(sample = rescaled_gaussians)) + stat_qq(col = "red") + stat_qq_line() + labs(title = "Central Limit Theorem QQ-Plot")
(z)

```

```{r}
#visualize ks tests
test_data = data.frame(method = c("Inverse CDF", "Box-Muller", "Central Limit Thm"), D_Statistic = c(0.01746531, 0.02621048, 0.02691662), P_value = c(0.9204866, 0.4979976, 0.4635318))
(test_data)
````







