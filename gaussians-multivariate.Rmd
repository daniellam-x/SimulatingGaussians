
Cholesky Decomposition
```{r}
#establish variance-covariance matrix of bivariate gaussian
sigma = rbind(c(1.0, 0.9),c(0.9,1.0))

#perform cholesky decomposition to get matrix A
A = t(chol(sigma))

#set the mean vector of r length for the bivariate gaussian
mu = c(0,0)
n = 1000

#populate Z matrix of n standard Gaussian distributions
Z = matrix(0, nrow = 2, ncol = n)
for (i in 1:n){
  norms = rnorm(length(mu))
  Z[1,i] = norms[1]
  Z[2,i] = norms[2]
}

#simulate bivariate Gaussian
X = (A %*% Z) + mu


#visualize distribution
hist(X[1,])
hist(X[2,])
plot(X[1,], X[2,])
c = cor(X[1,], X[2,])
c
```

The Gibbs Sampler
```{r}
#set up conditional distribution for p(x|y)
px_given_y = function(y, mu, sigma){
  m = mu[1] + sigma[2,1] / sigma[1,1] * (y - mu[2])
  s = sigma[1,1] - sigma[2,1] / sigma[2,2] * sigma[2,1]
  return (rnorm(1, mean = m, sd = s))
}

#set up conditional distribution for p(y|x)
py_given_x = function(x, mu, sigma){
  m = mu[2] + sigma[1,2] / sigma[2,2] * (x - mu[1])
  s = sigma[2,2] - sigma[1,2] / sigma[1,1] * sigma[1,2]
  return (rnorm(1, mean = m, sd = s))
}

#set mean, sample size, and variance-covariance matrix for bivariate gaussian
mus = c(0,0)
sigma = rbind(c(1.0, 0.9),c(0.9,1.0))
n = 5000

#initialize sample list in 2 dimensions
samples_x = rep(0, n)
samples_y = rep(0, n)

#initialize first y as mu and begin iterations
y = mu[2]
for (i in 1:n){
  x = px_given_y(y, mus, sigma)
  y = py_given_x(x, mus, sigma)
  samples_x[i] = x
  samples_y[i] = y
}

#set burn in number
burn = 4000
bsamples_x = samples_x[(burn + 1): length(samples_x)]
bsamples_y = samples_y[(burn + 1): length(samples_y)]

#visualize
hist(bsamples_x)
hist(bsamples_y)
plot(bsamples_x, bsamples_y)


```




